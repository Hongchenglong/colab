{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有两个神经网络，结构如下：\n",
    "\n",
    "DNN： 784-2048-784，BNN： 784-512-10\n",
    "\n",
    "将DNN的输出作为BNN的输入，串联成一个新的神经网络：784-2048-784-512-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T09:35:31.364483Z",
     "start_time": "2021-12-25T09:34:37.762374Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2048)              1607680   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 784)               1606416   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,214,096\n",
      "Trainable params: 3,214,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000234023963A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000234023963A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 15.6608 - accuracy: 0.0944\n",
      "model/dnn_model_mnist_epochs_1.h5保存完成\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "dataset = \"mnist\"\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# (X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 归一化\n",
    "# X_train = X_train / 255.\n",
    "# X_test = X_test / 255.\n",
    "\n",
    "dnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(784, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(4096, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "dnn_model.summary()\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "epochs = 1\n",
    "\n",
    "dnn_model.compile(optimizer=tf.optimizers.Adam(), loss=loss, metrics=['accuracy'])\n",
    "dnn_model.fit(X_train, y_train, epochs=epochs)\n",
    "\n",
    "dnn_model_path = \"model/dnn_model_\" + dataset + \"_epochs_\" + str(epochs) + \".h5\"\n",
    "dnn_model.save(dnn_model_path)\n",
    "print(dnn_model_path + \"保存完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T09:35:32.264371Z",
     "start_time": "2021-12-25T09:35:31.490370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2048)              1607680   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 784)               1606416   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,214,096\n",
      "Trainable params: 3,214,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.keras.models.load_model(dnn_model_path)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T09:35:49.122381Z",
     "start_time": "2021-12-25T09:35:32.376373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002345F74D438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002345F74D438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "bnn_X_train = dnn_model.predict(X_train)\n",
    "bnn_X_test = dnn_model.predict(X_test)\n",
    "bnn_X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:00:53.811389Z",
     "start_time": "2021-12-25T10:00:53.740229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "bnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:00:54.260463Z",
     "start_time": "2021-12-25T10:00:54.238467Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This optimizer does not have a default compilation method. Please make sure to call the correct .compile method before use.\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(os.getcwd())\n",
    "sys.path.append(str(path.parent))\n",
    "\n",
    "import BayesKeras\n",
    "import BayesKeras.optimizers as optimizers\n",
    "\n",
    "arg = {'eps': 0.11, 'lam': 0.25, 'rob': 0, 'opt': 'BBB', 'gpu': '-1'}\n",
    "\n",
    "eps = arg['eps']\n",
    "lam = arg['lam']\n",
    "rob = arg['rob']\n",
    "optim = arg['opt']\n",
    "gpu = arg['gpu']\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "inf = 2\n",
    "full_covar = False\n",
    "if (optim == 'VOGN'):\n",
    "    # was 0.25 for a bit\n",
    "    inf = 2\n",
    "    learning_rate = 0.35\n",
    "    decay = 0.0\n",
    "    opt = optimizers.VariationalOnlineGuassNewton()\n",
    "elif (optim == 'BBB'):\n",
    "    inf = 10\n",
    "    learning_rate = 0.45\n",
    "    decay = 0.0\n",
    "    opt = optimizers.BayesByBackprop()\n",
    "elif (optim == 'SWAG'):\n",
    "    learning_rate = 0.01\n",
    "    decay = 0.0\n",
    "    opt = optimizers.StochasticWeightAveragingGaussian()\n",
    "elif (optim == 'SWAG-FC'):\n",
    "    learning_rate = 0.01\n",
    "    decay = 0.0\n",
    "    full_covar = True\n",
    "    opt = optimizers.StochasticWeightAveragingGaussian()\n",
    "elif (optim == 'SGD'):\n",
    "    learning_rate = 1.0\n",
    "    decay = 0.0\n",
    "    opt = optimizers.StochasticGradientDescent()\n",
    "elif (optim == 'NA'):\n",
    "    inf = 2\n",
    "    learning_rate = 0.001\n",
    "    decay = 0.0\n",
    "    opt = optimizers.NoisyAdam()\n",
    "elif (optim == 'ADAM'):\n",
    "    learning_rate = 0.00001\n",
    "    decay = 0.0\n",
    "    opt = optimizers.Adam()\n",
    "elif (optim == 'HMC'):\n",
    "    learning_rate = 0.075\n",
    "    decay = 0.0\n",
    "    inf = 250\n",
    "    linear_schedule = False\n",
    "    opt = optimizers.HamiltonianMonteCarlo()\n",
    "\n",
    "# Compile the model to train with Bayesian inference\n",
    "if (rob == 0):\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "elif (rob != 0):\n",
    "    loss = BayesKeras.optimizers.losses.robust_crossentropy_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编译和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:00:54.482462Z",
     "start_time": "2021-12-25T10:00:54.390462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesKeras: Using implicit prior\n",
      "sha: (784, 512), std: 0.11293848786315641\n",
      "sha: (512, 10), std: 0.13975424859373686\n",
      "BayesKeras: Using implicit prior\n",
      "sha: (784, 512), std: 0.11293848786315641\n",
      "sha: (512, 10), std: 0.13975424859373686\n",
      "计算后验方差\n",
      "BayesKeras: Using passed loss_fn as the data likelihood in the KL loss\n"
     ]
    }
   ],
   "source": [
    "bnn_model = opt.compile(bnn_model, loss_fn=loss, learning_rate=learning_rate, epochs=1,\n",
    "                          batch_size=128, linear_schedule=True,\n",
    "                          decay=decay, robust_train=rob, inflate_prior=inf,\n",
    "                          burn_in=3, steps=25, b_steps=20, epsilon=eps, rob_lam=lam)  # , preload=\"SGD_FCN_Posterior_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:02:42.141550Z",
     "start_time": "2021-12-25T10:00:54.488463Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 469/469 [01:46<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: nan, acc: 0.099, val_loss: nan, val_acc: 0.098\n"
     ]
    }
   ],
   "source": [
    "# steps was 50\n",
    "# Train the model on your data\n",
    "bnn_model.train(bnn_X_train, y_train, bnn_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:02:42.297472Z",
     "start_time": "2021-12-25T10:02:42.254465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\T470\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# Save your approxiate Bayesian posterior\n",
    "bnn_model.save(\"%s_FCN_Posterior_%s_dnn_bnn\" % (optim, rob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:02:42.407480Z",
     "start_time": "2021-12-25T10:02:42.399462Z"
    }
   },
   "source": [
    "### 预测\n",
    "\n",
    "DNN的输出作为BNN的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:02:42.595461Z",
     "start_time": "2021-12-25T10:02:42.490463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = bnn_model.predict(bnn_X_test)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:02:42.611462Z",
     "start_time": "2021-12-25T10:02:42.598465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T10:02:42.942483Z",
     "start_time": "2021-12-25T10:02:42.930465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_pred[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-25T08:44:56.404445Z",
     "start_time": "2021-12-25T08:44:56.390447Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CertifiableBayesianInference",
   "language": "python",
   "name": "certifiablebayesianinference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
