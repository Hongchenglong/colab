{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_uncert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPC7K7pKt0YtY7b9h9Kl8lb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hongchenglong/colab/blob/main/CertifiableBayesianInference/FCN_Experiments/MNIST_uncert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htA-No-UcoSb",
        "outputId": "0af67ae5-fe73-44f1-bac4-3607b60de3d3"
      },
      "source": [
        "# 装载Google硬盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ImpjFjdczM3"
      },
      "source": [
        "import sys, os\n",
        "from pathlib import Path\n",
        "path = Path(os.getcwd())\n",
        "sys.path.append(str(path.parent))\n",
        "sys.path.append('/content/drive/MyDrive/ColabNotebooks/CertifiableBayesianInference')\n",
        "experiment = '/content/drive/MyDrive/ColabNotebooks/CertifiableBayesianInference/FCN_Experiments/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBDqWSZ5c1bA"
      },
      "source": [
        "# python3 MNIST_runner.py --eps 0.11 --lam 0.25 --rob 0 --opt HMC --gpu 0 &\n",
        "# python3 MNIST_runner.py --eps 0.11 --lam 0.25 --rob 2 --opt HMC --gpu 1 &\n",
        "\n",
        "# dict = {'eps': 0.11, 'lam': 0.25, 'rob': 0, 'opt': 'HMC', 'gpu': '0'}\n",
        "dict = {'eps': 0.11, 'lam': 0.25, 'rob': 2, 'opt': 'HMC', 'gpu': '1'}\n",
        "\n",
        "# epsilon:  the strength of the adversary, 在测试点周围多大的区域里考虑它的鲁棒性\n",
        "eps = dict['eps']\n",
        "# lamada: the probability of seeing the clean data (lambda = 1.0 means no adversarial data considered, lambda = 0.0 means only adversarial data considered)\n",
        "lam = dict['lam'] \n",
        "# robustness mode, 0:标准 1:IBP 2:PGD\n",
        "rob = dict['rob'] \n",
        "# the variational inference method\n",
        "optim = dict['opt']\n",
        "gpu = dict['gpu']\n",
        "\n",
        "inference = optim"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MkXrSMBc3MI",
        "outputId": "23e24dfa-89db-44c9-ba37-870032322128"
      },
      "source": [
        "import BayesKeras\n",
        "from BayesKeras import PosteriorModel\n",
        "from BayesKeras import analyzers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(F_train, yf_train), (Xf_test, yf_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "F_train = F_train/255.\n",
        "F_train = F_train.astype(\"float32\").reshape(-1, 28*28)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train/255.\n",
        "X_test = X_test/255.\n",
        "X_train = X_train.astype(\"float32\").reshape(-1, 28*28)\n",
        "X_test = X_test.astype(\"float32\").reshape(-1, 28* 28)\n",
        "\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "model = PosteriorModel(experiment + \"%s_FCN_Posterior_%s\"%(inference, rob))\n",
        "\n",
        "epistemic, aleatoric = analyzers.variational_uncertainty(model, X_test[0:num_images])\n",
        "auc = analyzers.auroc(model, X_test[0:num_images], y_test[0:num_images])\n",
        "\n",
        "print(\"ON MNIST\")\n",
        "print(\"-------------------------------\")\n",
        "print(\"Epistemic: \",np.mean(epistemic))\n",
        "print(\"Aleatoric: \",np.mean(aleatoric))\n",
        "print(\"AUC: \", auc)\n",
        "print(\"-------------------------------\")\n",
        "\n",
        "epistemic, aleatoric = analyzers.variational_uncertainty(model, F_train[0:num_images])\n",
        "auc = analyzers.auroc(model, F_train[0:num_images], yf_train[0:num_images])\n",
        "\n",
        "print(\"ON FasionMNIST\")\n",
        "print(\"-------------------------------\")\n",
        "print(\"Epistemic: \",np.mean(epistemic))\n",
        "print(\"Aleatoric: \",np.mean(aleatoric))\n",
        "print(\"AUC: \", auc)\n",
        "print(\"-------------------------------\")\n",
        "llr = analyzers.likelihood_ratio(model, X_test[0:num_images], F_train[0:num_images])\n",
        "print(\"LLR: \", llr)\n",
        "print(\"-------------------------------\")\n",
        "\n",
        "meth = analyzers.FGSM\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "adv = meth(model, X_test[0:num_images], eps=0.1, loss_fn=loss, num_models=10, direction=y_test[0:num_images])\n",
        "\n",
        "epistemic, aleatoric = analyzers.variational_uncertainty(model, adv)\n",
        "auc = analyzers.auroc(model, adv, y_test[0:num_images])\n",
        "print(\"ON Adversarial Examples\")\n",
        "print(\"-------------------------------\")\n",
        "print(\"Epistemic: \",np.mean(epistemic))\n",
        "print(\"Aleatoric: \",np.mean(aleatoric))\n",
        "print(\"AUC: \", auc)\n",
        "print(\"-------------------------------\")\n",
        "llr = analyzers.likelihood_ratio(model, X_test[0:num_images], adv)\n",
        "print(\"LLR: \", llr)\n",
        "print(\"-------------------------------\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] BayesKeras: Attempting to load a sample based posterior\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, None, None, 512)   401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, None, 10)    5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "BayesKeras detected the above model \n",
            " None\n",
            "Pred shape:  (35, 500, 10)\n",
            "ON MNIST\n",
            "-------------------------------\n",
            "Epistemic:  -1.1450375e-09\n",
            "Aleatoric:  0.0010201817\n",
            "AUC:  0.9786991019558233\n",
            "-------------------------------\n",
            "Pred shape:  (35, 500, 10)\n",
            "ON FasionMNIST\n",
            "-------------------------------\n",
            "Epistemic:  -3.2724798e-10\n",
            "Aleatoric:  0.0011630136\n",
            "AUC:  0.49646192836920405\n",
            "-------------------------------\n",
            "LLR:  0.9989085\n",
            "-------------------------------\n",
            "Pred shape:  (35, 500, 10)\n",
            "ON Adversarial Examples\n",
            "-------------------------------\n",
            "Epistemic:  -3.0770897e-10\n",
            "Aleatoric:  0.00012849606\n",
            "AUC:  0.884045689828665\n",
            "-------------------------------\n",
            "LLR:  1.0055768\n",
            "-------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPPKBieYdcw1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}